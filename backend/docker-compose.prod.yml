version: '3.9'

# ==============================================================================
# Production Docker Compose Configuration
# ==============================================================================
# This configuration is optimized for production deployment
#
# IMPORTANT:
# - Use environment-specific .env files (never commit with real credentials)
# - Consider using managed services (Supabase, Redis Cloud, etc.) for production
# - For Postgres, strongly recommend using managed Supabase instead of self-hosted
# - Ensure proper backup strategies for data volumes
# - Configure resource limits based on your infrastructure
# ==============================================================================

services:
  # ============================================================================
  # Redis - Queue and Cache
  # ============================================================================
  redis:
    image: redis:7-alpine
    container_name: volume-bot-redis
    restart: unless-stopped
    command: >
      redis-server
      --appendonly yes
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --requirepass ${REDIS_PASSWORD:-changeme}
    volumes:
      - redis_data:/data
    ports:
      - "${REDIS_PORT:-6379}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s
    networks:
      - volume-bot-network
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # ============================================================================
  # PostgreSQL - Database (Optional - Use Supabase in production)
  # ============================================================================
  # NOTE: For production, we strongly recommend using managed Supabase
  # This Postgres service is provided as a fallback option only
  postgres:
    image: postgres:16-alpine
    container_name: volume-bot-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-volumebot}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=en_US.UTF-8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/database-schema.sql:/docker-entrypoint-initdb.d/01-schema.sql:ro
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s
    networks:
      - volume-bot-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ============================================================================
  # API Service
  # ============================================================================
  api:
    build:
      context: ./backend/api
      dockerfile: Dockerfile
      target: production
    image: volume-bot-api:${VERSION:-latest}
    container_name: volume-bot-api
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - NODE_ENV=production
      - API_PORT=${API_PORT:-3001}
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379
      # Use Supabase in production (recommended)
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
      # Or use self-hosted Postgres (not recommended for production)
      # - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-changeme}@postgres:5432/${POSTGRES_DB:-volumebot}
      - MASTER_ENCRYPTION_KEY=${MASTER_ENCRYPTION_KEY}
      - CORS_ORIGIN=${CORS_ORIGIN:-*}
      # Sentry
      - SENTRY_DSN=${SENTRY_DSN:-}
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-production}
      - SENTRY_TRACES_SAMPLE_RATE=${SENTRY_TRACES_SAMPLE_RATE:-0.1}
      # OpenTelemetry
      - OTEL_ENABLED=${OTEL_ENABLED:-true}
      - OTEL_SERVICE_NAME=${OTEL_SERVICE_NAME:-volume-bot-api}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT:-}
      # Solana RPC
      - SOLANA_RPC_URL=${SOLANA_RPC_URL}
      - RPC_ENDPOINT=${RPC_ENDPOINT}
      - RPC_WEBSOCKET_ENDPOINT=${RPC_WEBSOCKET_ENDPOINT}
    ports:
      - "${API_PORT:-3001}:3001"
    depends_on:
      redis:
        condition: service_healthy
      # postgres:  # Uncomment if using self-hosted Postgres
      #   condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3001/v1/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 40s
    networks:
      - volume-bot-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s

  # ============================================================================
  # Worker Service (Scalable)
  # ============================================================================
  worker:
    build:
      context: ./backend/workers
      dockerfile: Dockerfile
      target: production
    image: volume-bot-worker:${VERSION:-latest}
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - NODE_ENV=production
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
      - MASTER_ENCRYPTION_KEY=${MASTER_ENCRYPTION_KEY}
      - WORKER_CONCURRENCY=${WORKER_CONCURRENCY:-5}
      - STATUS_AGGREGATOR_INTERVAL_SECONDS=${STATUS_AGGREGATOR_INTERVAL_SECONDS:-15}
      # Sentry
      - SENTRY_DSN=${SENTRY_DSN:-}
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-production}
      # Solana RPC
      - SOLANA_RPC_URL=${SOLANA_RPC_URL}
      - RPC_ENDPOINT=${RPC_ENDPOINT}
      - RPC_WEBSOCKET_ENDPOINT=${RPC_WEBSOCKET_ENDPOINT}
      # Jito
      - JITO_KEY=${JITO_KEY}
      - BLOCKENGINE_URL=${BLOCKENGINE_URL}
      - JITO_FEE=${JITO_FEE}
      # Trading config
      - BUY_LOWER_AMOUNT=${BUY_LOWER_AMOUNT:-0.001}
      - BUY_UPPER_AMOUNT=${BUY_UPPER_AMOUNT:-0.002}
      - BUY_INTERVAL_MIN=${BUY_INTERVAL_MIN:-2000}
      - BUY_INTERVAL_MAX=${BUY_INTERVAL_MAX:-4000}
      - DISTRIBUTE_WALLET_NUM=${DISTRIBUTE_WALLET_NUM:-5}
      - SELL_ALL_BY_TIMES=${SELL_ALL_BY_TIMES:-1}
    depends_on:
      redis:
        condition: service_healthy
      api:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "pgrep", "-f", "node dist/main.js"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 40s
    networks:
      - volume-bot-network
    deploy:
      # Scale workers based on load
      replicas: ${WORKER_REPLICAS:-2}
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s

# ==============================================================================
# Networks
# ==============================================================================
networks:
  volume-bot-network:
    driver: bridge

# ==============================================================================
# Volumes - Persistent Data
# ==============================================================================
volumes:
  redis_data:
    driver: local
  postgres_data:
    driver: local

# ==============================================================================
# PRODUCTION DEPLOYMENT NOTES
# ==============================================================================
#
# 1. Scaling Workers:
#    docker-compose -f docker-compose.prod.yml up -d --scale worker=5
#
# 2. View Logs:
#    docker-compose -f docker-compose.prod.yml logs -f [service_name]
#
# 3. Health Checks:
#    docker-compose -f docker-compose.prod.yml ps
#
# 4. Stop All Services:
#    docker-compose -f docker-compose.prod.yml down
#
# 5. Update and Restart:
#    docker-compose -f docker-compose.prod.yml pull
#    docker-compose -f docker-compose.prod.yml up -d --force-recreate
#
# 6. Backup Volumes:
#    docker run --rm -v volume-bot_redis_data:/data -v $(pwd):/backup alpine tar czf /backup/redis-backup.tar.gz /data
#
# 7. Resource Monitoring:
#    docker stats
#
# ==============================================================================
